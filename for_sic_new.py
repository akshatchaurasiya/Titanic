# -*- coding: utf-8 -*-
"""for_SIC_(4)_(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ivO4HPN2WTLl5rMZ38svq3teolin37xF
"""

import pandas as pd
df=pd.read_csv("Titanic-Dataset.csv")

df.head()

print(df.shape)

df.info()

df.describe()

df.isnull().sum()

df["Age"].fillna(df.Age.mean(), inplace= True)

print(df.Age.isna().sum())

df.isna().sum()

df.Embarked.fillna(df.Embarked.mode()[0], inplace=True)

df.Cabin.fillna(df.Cabin.mode()[0], inplace=True)

df.info()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
for col in ["Sex", "Embarked"]:
  df[col]=le.fit_transform(df[col])

df.head()

d=["Cabin","PassengerId", "Name", "Ticket"]
df.drop(d, axis=1, inplace=True)

df.head()

cat_col=["Sex", "Embarked"]
df_update=pd.get_dummies(df, columns=cat_col, drop_first=True)

df_update.shape

df_update.head()

pd.Index=["Pclass", "Age", "SibSp","Parch", "Fare", "Sex_1", "Embarked_1", "Embarked_2"]
x=df_update[pd.Index]
y=df_update["Survived"]

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=0.2, random_state=42)

x_train.shape, x_test.shape

y_train.shape, y_test.shape

from sklearn.linear_model import LogisticRegression

log_model= LogisticRegression()
log_model.fit(x_train, y_train)

from sklearn.metrics import accuracy_score

# from sklearn.linear_model import LogisticRegression
# log_model=LogisticRegression()
# log_model.fit(x_train, y_train)
# train_pred=log_model.predict(x_train)
# test_pred=log_model.predict(x_test)

# log_train_acc = accuracy_score(y_train,train_pred)
# log_test_acc = accuracy_score(y_test, test_pred)

# print(log_train_acc)
# print(log_test_acc)

from sklearn.tree import DecisionTreeClassifier
dt_model = DecisionTreeClassifier(
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=3,
    random_state=42
  )
dt_model.fit(x_train,y_train)
train_pred = dt_model.predict(x_train)
test_pred = dt_model.predict(x_test)

dt_train_acc = accuracy_score(y_train, train_pred)
dt_test_acc = accuracy_score(y_test, test_pred)

print(dt_train_acc)
print(dt_test_acc)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm=confusion_matrix(y_test, log_model.predict(x_test))
sns.heatmap(cm, annot=True, cmap="Blues", fmt="d")

from sklearn.metrics import classification_report
print(classification_report(y_test, log_model.predict(x_test)))

for depth in range(2,11):
  model = DecisionTreeClassifier(max_depth=depth)
  model.fit(x_train, y_train)
  acc=accuracy_score(y_test, model.predict(x_test))
  print(f"{depth}: {acc:.3f}")

from sklearn .ensemble import RandomForestClassifier
rf_model=RandomForestClassifier(random_state=42)
rf_model.fit(x_train,y_train)

y_predrf=rf_model.predict(x_test)

train_acc=rf_model.score(x_train, y_train)
test_acc=accuracy_score(y_test,y_predrf )
print(train_acc)
print(test_acc)

cm_rf= confusion_matrix(y_test, y_predrf)
print("confusion matrux")
print(cm_rf)
print(classification_report(y_test, y_predrf))

#Cross validation
from sklearn.model_selection import cross_val_score
scores= cross_val_score(RandomForestClassifier(), x_train, y_train, cv=5)
print("cv_score:", scores)
print("Average cv Score:", scores.mean())

from sklearn.model_selection import GridSearchCV
param_grid={"n_estimators": [50,100,150,200],
            "max_depth":["None", 3, 5 , 10 , 12],
            "min_samples_split":[2,4,6,8]

}

grid=GridSearchCV(RandomForestClassifier(),  param_grid, cv=5)
grid.fit(x_train, y_train)
print("Best parameters:", grid.best_params_)
print("Best score:", grid.best_score_)

best_model= grid.best_estimator_
y_pred_best= best_model.predict(x_test)

y_pred_best

print(classification_report(y_test,y_pred_best))

cm_rf_best= confusion_matrix(y_test, y_pred_best)
print("confusion matrix")
print(cm_rf_best)

test_acc=accuracy_score(y_test,y_pred_best )

test_acc

from sklearn.neighbors import KNeighborsClassifier
for i in range(3,9):
  knn= KNeighborsClassifier(n_neighbors=i)
  knn.fit(x_train, y_train)
  print(f"KNN TEST  ACCURACY on {i} nighbors:  {knn.score(x_test, y_test)}")

from xgboost import XGBClassifier
xgb=XGBClassifier(use_label_encoder=False, eval_metrics="logless")
xgb.fit(x_train, y_train)
print("Xgboost test acc", xgb.score(x_test, y_test))

from sklearn.svm import SVC
svm=SVC()
svm.fit(x_train, y_train)
print(svm.score(x_test, y_test))

from sklearn.ensemble import AdaBoostClassifier
ada=AdaBoostClassifier()
ada.fit(x_train,y_train)
print(ada.score(x_test, y_test))

models={
    "Logistic Regression": log_model,
    "Dec Tree:": dt_model,
    "Random Forest": rf_model,
    "KNN":knn,
    "XG boost": xgb,
    "svm": svm,
    "Ada Boost": ada}
for name, model in models.items():
  print(f"{name}: {model.score(x_test, y_test):.4f}")

y_pred = ada.predict(x_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

params={
    "n_estimators": [30,40,50,100,150],
    "learning_rate": [0.01, 0.05,0.1, 1, 1.05]

}
grid= GridSearchCV(AdaBoostClassifier(), param_grid= params,cv=5)
grid.fit(x_train, y_train)
print("Best Parametrs: ", grid.best_params_)
print("Best Score:", grid.best_score_)

import joblib

# Save model
joblib.dump(model, "loan_model.pkl")

pip install streamlit pyngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import joblib
# import numpy as np
# import pandas as pd
# model=joblib.load("loan_model (1).pkl")
# 
# st.title("Loan Approval Prediction")
# st.write("Enter your Details")
# gender=st.number_input("enter your gender in 0 and 1 , 1 for male")
# married=st.number_input("enter your marital status in 0 and 1 , 1 for married")
# Graduate= st.number_input("enter if you are graduate or not status in 0 and 1 , 1 for you are not")
# Self_Employed= st.number_input("enter if you are self employed or not status in 0 and 1 , 1 for if you are")
# income= st.number_input("enter your income")
# loan_amount= st.number_input("enter loan amount")
# laon_amount_term= st.number_input("enter your loan amount term")
# credit_history=st.selectbox("Credit History", [0,1])
# property_area= st.number_input("enter your property area")
# 
# if st.button("predict"):
#   features=np.array([['Male', 'Married', 'Non Graduate', 'Self_Employed', 'ApplicantIncome',
#        'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area']])
#   prediction=model.predict(features[0])
#   if prediction==1:
#     st.success("Loan APPROVED")
#   else:
#     st.error("Not elegible for the loan")

x_train.columns
[1, 0,1,2,]

from pyngrok import ngrok
!ngrok config add-authtoken "3197oRHWhF8lMkGw2oKy475jlA9_5D9jqq2PqhXuq4irA96Kj" # change this code to yours

# start tunnel
public_url= ngrok.connect(addr="8501")
print("Public URL: ", public_url)
!streamlit run streamlit_app.py --server.port 8501-&>dev/null &